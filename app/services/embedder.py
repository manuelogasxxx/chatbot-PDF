from typing import List, Dict
from fastembed import TextEmbedding

#load the embedder model, this coulb be change anytime
embedder = TextEmbedding(model_name="sentence-transformers/all-MiniLM-L6-v2")

def embed_chunks(chunks):
    return [embedder.embed(doc)[0] for doc in chunks]



#finally each embedding is stored in chroma

def generar_embeddings(chunks: List[Dict]) -> List[Dict]:
    """
    Enriquece los chunks usando FastEmbed (ligero, r√°pido, sin PyTorch pesado).
    """
    #print(f"‚öôÔ∏è Cargando modelo FastEmbed: {model_name}...")
    
    # 1. Inicializaci√≥n del modelo
    # FastEmbed descarga autom√°ticamente la versi√≥n cuantizada (ONNX) del modelo.
    # threads=None usa todos los cores disponibles por defecto.
    #model = TextEmbedding(model_name=model_name)
    
    # Extraer textos
    textos = [c['page_content'] for c in chunks]
    
    print("‚öôÔ∏è Generando vectores (Stream)...")
    
    # 2. Generaci√≥n de Embeddings
    # IMPORTANTE: model.embed() devuelve un GENERADOR, no una lista inmediata.
    # Esto ahorra mucha memoria RAM.
    embeddings_generator = embedder.embed(textos)
    
    datos_vectorizados = []
    
    # 3. Iteraci√≥n simult√°nea (Zip)
    # Usamos zip para recorrer la lista de chunks original y el generador de vectores al mismo tiempo.
    for i, (chunk, vector) in enumerate(zip(chunks, embeddings_generator)):
        nuevo_chunk = chunk.copy()
        
        # El vector viene como numpy array, lo convertimos a lista para JSON/DB
        nuevo_chunk['vector'] = vector.tolist()
        
        # Generar ID √∫nico basado en la fuente y el √≠ndice
        # Usamos .get para evitar errores si 'metadata' no tiene 'source'
        source = chunk['metadata'].get('source', 'unknown')
        nuevo_chunk['id'] = f"{source}_{i}"
        
        datos_vectorizados.append(nuevo_chunk)
        
    # Verificaci√≥n de seguridad por si la lista est√° vac√≠a
    if datos_vectorizados:
        dim = len(datos_vectorizados[0]['vector'])
        print(f"‚úÖ Vectorizaci√≥n completada. {len(datos_vectorizados)} chunks procesados.")
        print(f"üìä Dimensi√≥n del vector: {dim}")
    else:
        print("‚ö†Ô∏è No se generaron vectores (lista de chunks vac√≠a).")

    return datos_vectorizados

#this function embedd a query.