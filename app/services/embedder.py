from typing import List, Dict
from fastembed import TextEmbedding
import chromadb

#load the embedder model, this coulb be change anytime
embedder = TextEmbedding(model_name="sentence-transformers/all-MiniLM-L6-v2")




def create_embeddings(chunks: List[Dict]) -> List[Dict]:
    #print(f"‚öôÔ∏è Cargando modelo FastEmbed: {model_name}...")
    
    # 1. Inicializaci√≥n del modelo
    # FastEmbed descarga autom√°ticamente la versi√≥n cuantizada (ONNX) del modelo.
    # threads=None usa todos los cores disponibles por defecto.
    #model = TextEmbedding(model_name=model_name)
    
    # Extraer textos
    textos = [c['page_content'] for c in chunks]
    
    print("‚öôÔ∏è Generando vectores (Stream)...")
    
    # 2. Generaci√≥n de Embeddings
    # IMPORTANTE: model.embed() devuelve un GENERADOR, no una lista inmediata.
    # Esto ahorra mucha memoria RAM.
    embeddings_generator = embedder.embed(textos)
    
    datos_vectorizados = []
    
    # 3. Iteraci√≥n simult√°nea (Zip)
    # Usamos zip para recorrer la lista de chunks original y el generador de vectores al mismo tiempo.
    for i, (chunk, vector) in enumerate(zip(chunks, embeddings_generator)):
        nuevo_chunk = chunk.copy()
        
        # El vector viene como numpy array, lo convertimos a lista para JSON/DB
        nuevo_chunk['vector'] = vector.tolist()
        
        # Generar ID √∫nico basado en la fuente y el √≠ndice
        # Usamos .get para evitar errores si 'metadata' no tiene 'source'
        source = chunk['metadata'].get('source', 'unknown')
        nuevo_chunk['id'] = f"{source}_{i}"
        
        datos_vectorizados.append(nuevo_chunk)
        
    # Verificaci√≥n de seguridad por si la lista est√° vac√≠a
    if datos_vectorizados:
        dim = len(datos_vectorizados[0]['vector'])
        print(f"‚úÖ Vectorizaci√≥n completada. {len(datos_vectorizados)} chunks procesados.")
        print(f"üìä Dimensi√≥n del vector: {dim}")
    else:
        print("‚ö†Ô∏è No se generaron vectores (lista de chunks vac√≠a).")

    return datos_vectorizados

def load_collection(path_db="chromaDB", collection_name="myDocuments"):
    client = chromadb.PersistentClient(path=path_db)
    collection = client.get_collection(name=collection_name)
    return collection
#this function embedd a query and its part of the main RAG
#collection correspond to the return value of chroma.py function
def buscar_similares(archivo,collection, texto_consulta, embedding_model, k=5):
    # FastEmbeddings ‚Üí generator ‚Üí list
    query_embedding = next(embedding_model.embed(texto_consulta))

    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=k,
        where={"source": archivo}
    )

    return results

